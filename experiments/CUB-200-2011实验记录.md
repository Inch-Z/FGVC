## 在CUB-200-2011上的注意力模块对比实验

### 1：加在最后一层(全局平均池化压缩前)的结果

#### 实验日期(2.14)

| resnet50 | +CBAM(sa残差连接) | resnet50<br/>input_size=224<br/>(FC层-init_lr=1e-3)<br/>(backbone-init_lr=1e-4)) |
| :------: | :---------------: | :----------------------------------------------------------: |
|  78.91%  |      78.75%       |                          **79.93%**                          |

**分析与展望：**

1. 使用224的大小作为图片输入，能达到约79%的准确率。



### 2：PMG尝试实验

### 实验日期(3.10 - 3.16)
|               Model(input 448) - 单损失函数                |          Test acc(%)           |
| :--------------------------------------------------------: | :----------------------------: |
|                      resnet(Baseline)                      |           84.12(136)           |
|     L3 + L4 + L5 + 448 init_lr=1e-4(pmg*10，T_max=10)      |   83.91(44) - 训练集迅速拟合   |
|  L3 + L4 + L5 + paper_448 init_lr=1e-4(pmg*10，T_max=10)   | **86.12(44)** - 训练集迅速拟合 |
| L3 + L4 + L5 + se_paper_448 init_lr=1e-4(pmg*10，T_max=10) |   86.07(42) - 训练集迅速拟合   |

**分析与展望：**

1. 使用448的大小作为图片输入，能达到84.12%的准确率，对比224时提升了约5%。
2. 使用论文推荐的预处理方法，多层concat，能达到86.12(+2.0%)的准确率。





### 3：PMG复现实验

### 实验日期(3.13 - 3.17)

|                 Model(input 448) - 4损失函数                 |     Test acc(%)      |
| :----------------------------------------------------------: | :------------------: |
|                       resnet(Baseline)                       |    **84.12(136)**    |
| 完整图片  L3 + L4 + L5  init_lr=1e-4(pmg*10，concat_fc * 10, T_max=10) |      81.86(108)      |
| 完整图片  L3 + L4 + L5  init_lr=5e-4(pmg*10，concat_fc * 10, T_max=10) | 77.06(24) - 卡在鞍点 |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=5e-4(pmg*10，concat_fc * 10, T_max=10) |      82.97(26)       |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=2e-4(pmg*10，concat_fc * 10, T_max=10) |      86.37(30)       |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=2e-4(pmg*10，concat_fc * 10, T_max=10)  + 每个分类前Dropout(0.2) |      84.31(38)       |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=2e-4(pmg*10，concat_fc * 10, T_max=10)  + 每个分类前Dropout(0.5) |  79.89(57) - 欠拟合  |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=2e-4(pmg*10，all_fc * 10, T_max=10) - 完全一模一样复现 |    **88.21(45)**     |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=1e-4(pmg*10，all_fc * 10, T_max=10) - 每个分类前Dropout(0.2) |      87.87(161)      |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=2e-4(pmg*10，all_fc * 10, T_max=10) - 去掉pmg_conv |      87.50(79)       |
| paper的图片切块打乱 - L3 + L4 + L5  init_lr=1e-4(pmg*10，all_fc * 10, T_max=10) - 仅训练concat层 |      86.69(170)      |

**分析与展望：**

1. 学习率的设置非常重要。
2. 渐进式的效果很好，完全复现PMG原文可达到88.21%的准确率。
3. 利用dropout防止过拟合效果不佳。







### 4：PMG注意力模块对比实验

### 实验日期(3.16 - 3.25)

#### ECCV-PMG(backbone-lr=1e-4) 

|                Model(input 448) - 单损失函数                 |  Test acc(%)   |
| :----------------------------------------------------------: | :------------: |
|                   resnet<u>(Baseline1)</u>                   |   84.12(136)   |
|           ECCV-PMG<u>(Baseline2, init_lr=1e-4)</u>           |   88.38(177)   |
| ECCV-PMG<u>(Baseline3, init_lr=1e-4, T.Normalize:ImageNet)</u> | **88.80**(178) |
|           ECCV-PMG<u>(Baseline3, init_lr=2e-5)</u>           | **88.40**(159) |
| ECCV-PMG<u>(Baseline2, init_lr=1e-4, T.Normalize:ImageNet))</u> - avgpool 代替 maxpool |   84.41(104)   |
|                                                              |                |
|                + SENet(num=1, lr=<u>1e-4</u>)                | **88.66**(124) |
|                + SENet(num=1, lr=<u>1e-3</u>)                | **88.64**(86)  |
|                + SENet(num=1, lr=<u>1e-2</u>)                |   88.56(198)   |
|                                                              |                |
|          + SENet(num=1, lr=<u>1e-4</u>) + short-cut          | **88.76**(78)  |
|          + SENet(num=1, lr=<u>1e-3</u>) + short-cut          |   88.54(113)   |
| + SENet(num=1, lr=<u>1e-4</u>) + short-cut, T.Normalize:ImageNet) |   88.42(158)   |
|                                                              |                |
|          + SENet(num=3, lr=<u>1e-4</u>) + short-cut          | **88.47**(158) |
|          + SENet(num=3, lr=<u>1e-3</u>) + short-cut          |   88.32(153)   |
|          + SENet(num=3, lr=<u>1e-2</u>) + short-cut          | **88.61**(167) |
|                                                              |                |
|          + CBAM(num=1, lr=<u>1e-4</u>) + short-cut           | **88.73**(154) |
|          + CBAM(num=3, lr=<u>1e-4</u>) + short-cut           |   88.49(101)   |
|  + CBAM_easy_DCT_Spatial(num=3, lr=<u>1e-4</u>) + short-cut  | **88.82**(162) |
|                                                              |                |
|          +FcaNet(num=1, lr=<u>1e-4</u>) + short-cut          | **88.78**(145) |

**分析与展望：**

1. 使用ImageNet的归一化，效果能提升0.6%。
2. 添加注意力模块是有效的，但提升微弱。





### 5：PMG层次权重自适应实验

### 实验日期(3.23 - 3.25)

#### ECCV-PMG(backbone-lr=1e-4) 

|                Model(input 448) - 单损失函数                 |  Test acc(%)   |
| :----------------------------------------------------------: | :------------: |
|                   resnet<u>(Baseline1)</u>                   |   84.12(136)   |
|           ECCV-PMG<u>(Baseline2, init_lr=1e-4)</u>           |   88.38(177)   |
|                  + learning_weight(lr * 10)                  |   88.56(112)   |
|            + learning_weight(lr * 10) + short-cut            | **88.85**(122) |
|           + learning_weight(lr * 100) + short-cut            | **88.70**(147) |
| + learning_weight(lr * 10) + short-cut & <br>预测outputs_com =   weights[0] * outputs1 + weights[1] * outputs2 + weights[3] * outputs3 + outputs_concat |   88.14(103)   |

**分析与展望：**

1. 使用自适应权重分配有效，对比baseline提升约0.7%。



### 6：不同碎度的图片PMG实验

### 实验日期(3.23 - 3.26)

#### ECCV-PMG(backbone-lr=1e-4) 

|      Model(input 448) - 单损失函数       |       Test acc(%)       |
| :--------------------------------------: | :---------------------: |
|         resnet<u>(Baseline1)</u>         |       84.12(136)        |
| ECCV-PMG<u>(Baseline2, init_lr=1e-4)</u> |       88.38(177)        |
|              PMG(jigsaw=1)               |       88.13(159)        |
|              PMG(jigsaw=2)               |     **88.73**(148)      |
|              PMG(jigsaw=4)               |     **88.40**(117)      |
|              PMG(jigsaw=8)               |       86.21(160)        |
|              PMG(jigsaw=16)              | 72.13(51) - L1-L3欠拟合 |
|      PMG(jigsaw=16, val_jigsaw=16)       |       73.38(101)        |

**分析与展望：**

1. 探究不同的切块模式，发现ECCV2020-PMG原文中的实验缺陷，实际上当jigsaw=2时效果最好，能到达88.73%，对比完全复现提升0.6%，并不需要融合。





### 7：渐进式FPN层次对比

#### 7.1 CVPR-FPN(backbone-lr=1e-4) 

#### 实验日期(3.27 - 3.28)

| Model(input 448) - 单损失函数  |  Test acc(%)   |
| :----------------------------: | :------------: |
|    resnet<u>(Baseline1)</u>    |   84.12(136)   |
|  L2+L3+L4+L5+Concat - 训练5层  |   84.48(57)    |
| Concat(maxpool) - 训练concat层 | **85.48**(198) |
| Concat(avgpool) - 训练concat层 |   83.86(176)   |
|         L4 - 训练L4层          |   84.36(133)   |

**分析与展望：**

1. 再次验证了，多层concat是有效的。
2. 反FPN(R-FPN)或许更适合细粒度分类的思想



#### 7.2 R-FPN调参实验(backbone-lr=1e-4) 

#### 实验日期(3.27 - 3.30)

|             Model(input 448) - 单损失函数              |  Test acc(%)   |
| :----------------------------------------------------: | :------------: |
|                resnet<u>(Baseline1)</u>                |   84.12(136)   |
|             Concat(maxpool) - 训练concat层             |   83.19(36)    |
|              L2+L3+L4+L5+Concat - 训练5层              | **86.71**(120) |
| L2+L3+L4+L5+Concat - 训练5层 (去掉每层后的smooth卷积)  | **86.50**(121) |
| L2+L3+L4+L5+Concat - 训练5层(分类层仅用简单一层全连接) |   83.78(114)   |



#### 7.3 R-FPN层次递进实验(backbone-lr=1e-4)

|            Model(input 448) - 多损失函数             |  Test acc(%)   |
| :--------------------------------------------------: | :------------: |
|               resnet<u>(Baseline1)</u>               |   84.12(136)   |
| L2+L3+L4+L5+Concat - 训练5层(每层的out_channel=256)  | **86.71**(120) |
| L2+L3+L4+L5+Concat - 训练5层(每层的out_channel=512)  |                |
| L2+L3+L4+L5+Concat - 训练5层(每层的out_channel=1024) |                |

####  



#### 7.4 R-FPN层次递进实验(backbone-lr=1e-4, out_channel=256) 

#### 实验日期(3.29 - 3.31)

| Model(input 448) - 多损失函数 | Test acc(%) |
| :---------------------------: | :---------: |
|   resnet<u>(Baseline1)</u>    | 84.12(136)  |
|      Concat+L5+L4+L3+L2       |             |
|        Concat+L5+L4+L3        |             |
|         Concat+L5+L4          |             |
|           Concat+L5           |             |
|                               |             |
|                               |             |



### 8: PMG结合API-Net交互思想——PMGI-Net

####　实验日期（4.4 - ）

|      Model(input 448) - 多损失函数       |          训练函数           | bs   | Test acc(best-epoch) |
| :--------------------------------------: | :-------------------------: | ---- | :------------------: |
|       resnet-50<u>(Baseline1)</u>        |                             | 32   |      84.12(136)      |
| ECCV-PMG<u>(Baseline2, init_lr=1e-4)</u> |      PMGI_Net_train.py      | 32   |      88.38(177)      |
|             PMGI-V1(maxpool)             |      PMGI_Net_train.py      |      |                      |
|             PMGI-V1(avgpool)             |      PMGI_Net_train.py      |      |                      |
|              PMGI-V1-Extend              |      PMGI_Net_train.py      |      |                      |
|             PMGI-V2(maxpool)             |    PMGI_Net_V2_train.py     |      |                      |
|             PMGI-V2(avgpool)             |    PMGI_Net_V2_train.py     |      |                      |
|              PMGI-V2-Extend              |    PMGI_Net_V2_train.py     |      |                      |
|        PMGI-V3(resnet-50-maxpool)        |      PMGI_Net_train.py      | 32   |      88.33(184)      |
|        PMGI-V3(resnet-50-avgpool)        |      PMGI_Net_train.py      |      |                      |
|       PMGI-V3(resnet-101-maxpool)        |      PMGI_Net_train.py      | 32   |      89.06(126)      |
|       PMGI-V3(resnet-101-avgpool)        |      PMGI_Net_train.py      |      |                      |
|              PMGI-V3-Extend              |      PMGI_Net_train.py      |      |                      |
|        PMGI-V4(features-size=512)        |      PMGI_Net_train.py      | 32   |      86.61(49)       |
|       PMGI-V4(features-size=8192)        |      PMGI_Net_train.py      | 32   |      86.50(101)      |
|                 PMGI-V5                  |    PMGI_Net_V5_train.py     |      |                      |
|             PMGI-V6(avgpool)             |    PMGI_Net_V5_train.py     | 64   |      87.28(158)      |
|             PMGI-V6(maxpool)             |    PMGI_Net_V5_train.py     | 32   |  84.30(53) - by印棋  |
|       PMGI-V6_Extend(非渐进式训练)       | PMGI_Net_V6_Extend_train.py |      |                      |
|             PMGI-V7(maxpool)             |    PMGI_Net_V7_train.py     | 64   |         ≈87          |
|             PMGI-V7(avgpool)             |    PMGI_Net_V7_train.py     |      |                      |
|              PMGI-V7-Extend              | PMGI_Net_V7_Extend_train.py |      |                      |
|             PMGI-V8(maxpool)             |    PMGI_Net_V7_train.py     |      |                      |
|             PMGI-V8(avgpool)             |    PMGI_Net_V7_train.py     |      |                      |
|                                          |                             |      |                      |
|                                          |                             |      |                      |
|                                          |                             |      |                      |